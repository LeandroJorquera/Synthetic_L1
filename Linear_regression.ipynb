{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b6fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import pickle\n",
    "import umap\n",
    "import scipy.sparse as sparse\n",
    "from scipy.io import mmwrite\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80093be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_reader(path):\n",
    "    emb_input = pd.read_pickle(path)\n",
    "    \n",
    "    return emb_input\n",
    "\n",
    "def reformat_pickle(emb_input):\n",
    "    \"\"\"Change every dash (-) by underscore to allow datasets merging\"\"\"\n",
    "    \n",
    "    reformatted_emb = {}\n",
    "    for k, v in emb_input.items():\n",
    "        new_k = k.replace('-', '_')\n",
    "        v = v\n",
    "        reformatted_emb[new_k] = v\n",
    "        \n",
    "    return reformatted_emb\n",
    "\n",
    "def reformat_df(ORF2_counts):\n",
    "    \"\"\"Change every dash (-) and dot (.) by underscore (_) to allow datasets merging\"\"\"\n",
    "    \n",
    "    reformatted_counts_dict = {}\n",
    "    counts = ORF2_counts['Non_redundant']\n",
    "    names = ORF2_counts['ID']\n",
    "    for i in range(len(ORF2_counts)):\n",
    "        number = counts[i]\n",
    "        ID = names[i]\n",
    "        not_dash = ID.replace('-', '_')\n",
    "        clean = not_dash.replace('.', '_')\n",
    "        #print(clean)\n",
    "        reformatted_counts_dict[clean] = number\n",
    "        #reformatted_counts_dict\n",
    "    \n",
    "    reformatted = pd.DataFrame.from_dict(reformatted_counts_dict, orient='index')\n",
    "    reformatted_counts = reformatted.reset_index()\n",
    "    reformatted_counts.columns = ['ID', 'Non_redundant']\n",
    "    \n",
    "    return reformatted_counts\n",
    "    \n",
    "def pickle_to_matrix(reformatted_emb):    # Reading pickle file containing embeddings\n",
    "    matrix_inverted = pd.DataFrame(reformatted_emb)  # Create df from emb dict\n",
    "    matrix = matrix_inverted.transpose()  # Invert rows and columns to make it fit for Anndata object\n",
    "    #matrix.index = [\"dimension\" + str(i) for i in range(1, matrix.shape[0]+1)]  # dimension as rows, each entry as a column\n",
    "    \n",
    "    return matrix \n",
    "\n",
    "def match_ID(matrix, reformatted_counts):\n",
    "    \"\"\"Matching matrix (embs) and IDs from counts file to use embs observations with counts associated (all)\"\"\"\n",
    "    \n",
    "   #matched_IDs = matrix.loc[:, matrix.index.isin(reformatted_counts[\"ID\"].values)]\n",
    "    matched_emb = matrix.loc[matrix.index.isin(reformatted_counts['ID'].values)]\n",
    "    matched_counts = reformatted_counts.loc[reformatted_counts['ID'].isin(matrix.index)] \n",
    "    \n",
    "    return matched_emb, matched_counts\n",
    "\n",
    "def extract_weights(matched_emb):\n",
    "    \"\"\"Extracting PC weights with sklearn (from embeddings file)\"\"\"\n",
    "    \n",
    "    pca = PCA()  # Define PCA function\n",
    "    my_pca = pca.fit_transform(matched_emb)   # Scale data and apply PCA on embeddings df\n",
    "    dataframe_pca = pd.DataFrame(my_pca)  # Convert to df\n",
    "    \n",
    "    df_pca_loadings = pd.DataFrame(pca.components_) # Show Principal Components Weights (Eigenvectors)\n",
    "    a = df_pca_loadings.describe() # Print mean of every dimension (column) for all sequences \n",
    "    b = pd.DataFrame(a.iloc[1])       # Select mean data row (2nd)\n",
    "    c = b.reset_index()    #Displace index, rename columns and sort\n",
    "    c.columns = ['Dimension', 'Weight']\n",
    "    eigenvectors = c.sort_values(by=['Weight'], ascending=False)\n",
    "    \n",
    "    return eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read pickle file containing embeddings and reformat to remove dash that block merge\n",
    "path = '/Users/leandro/Desktop/ai_data/data/embeddings_v2.pickle'\n",
    "emb_input = pickle_reader(path)\n",
    "reformatted_emb = reformat_pickle(emb_input)\n",
    "#reformatted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba3ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read ORF2_counts file and reformat to remove dash and dots by underscore\n",
    "path_counts = '/Users/leandro/Desktop/ai_data/data/ORF2p_counts.csv'\n",
    "ORF2_counts = pd.read_csv(path_counts)\n",
    "reformatted_counts = reformat_df(ORF2_counts)\n",
    "#reformatted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3478b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Creating matrix from reformatted_emb dict and filtering counts and emb dataset to same length\n",
    "matrix = pickle_to_matrix(reformatted_emb)\n",
    "#matrix\n",
    "matched_emb = match_ID(matrix, reformatted_counts)[0]\n",
    "#matches_emb\n",
    "matched_counts = match_ID(matrix, reformatted_counts)[1]\n",
    "#matched_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e1cae3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 720 720\n"
     ]
    }
   ],
   "source": [
    "print(len(matrix.index), len(matched_emb.index), len(matched_counts.index))  # Test number of matchs between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10b99d",
   "metadata": {},
   "source": [
    "**Extracting PC weights with sklearn (from embeddings file)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ab465a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors = extract_weights(matched_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ba38efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.003141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>211</td>\n",
       "      <td>0.003136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>628</td>\n",
       "      <td>-0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>855</td>\n",
       "      <td>-0.003161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.003285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>-0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>587</td>\n",
       "      <td>-0.003817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dimension    Weight\n",
       "369        369  0.003191\n",
       "944        944  0.003189\n",
       "198        198  0.003141\n",
       "211        211  0.003136\n",
       "377        377  0.002939\n",
       "..         ...       ...\n",
       "628        628 -0.003039\n",
       "855        855 -0.003161\n",
       "19          19 -0.003285\n",
       "62          62 -0.003570\n",
       "587        587 -0.003817\n",
       "\n",
       "[1024 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86adf28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46 0.11 0.09 0.05 0.04 0.04 0.03 0.02 0.02 0.02]\n"
     ]
    }
   ],
   "source": [
    "# Percentage of variance explainedw with each PC (correlates to PCA made with scanpy)\n",
    "print(pca.explained_variance_ratio_.round(2)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d45fc50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principal Components Weights (Eigenvectors)\n",
    "len(df_pca_loadings.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
