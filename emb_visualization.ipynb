{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pickle\n",
    "import scipy.sparse as sparse\n",
    "from scipy.io import mmwrite\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scanpy as sc\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80093be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_reader(path):\n",
    "    emb_input = pd.read_pickle(path)\n",
    "    return emb_input\n",
    "\n",
    "def reformat_pickle(emb_input):\n",
    "    \"\"\"Change every dash (-) by underscore to allow datasets merging\"\"\"\n",
    "    reformatted_emb = {}\n",
    "    for k, v in emb_input.items():\n",
    "        new_k = k.replace('-', '_')\n",
    "        v = v\n",
    "        reformatted_emb[new_k] = v\n",
    "    return reformatted_emb\n",
    "\n",
    "def reformat_df(ORF2_counts):\n",
    "    \"\"\"Change every dash (-) and dot (.) by underscore (_) to allow datasets merging\"\"\"\n",
    "    reformatted_counts_dict = {}\n",
    "    counts = ORF2_counts['Non_redundant']\n",
    "    names = ORF2_counts['ID']\n",
    "    for i in range(len(ORF2_counts)):\n",
    "        number = counts[i]\n",
    "        ID = names[i]\n",
    "        not_dash = ID.replace('-', '_')\n",
    "        clean = not_dash.replace('.', '_')\n",
    "        #print(clean)\n",
    "        reformatted_counts_dict[clean] = number\n",
    "        #reformatted_counts_dict\n",
    "    \n",
    "    reformatted = pd.DataFrame.from_dict(reformatted_counts_dict, orient='index')\n",
    "    reformatted_counts = reformatted.reset_index()\n",
    "    reformatted_counts.columns = ['ID', 'Non_redundat']\n",
    "    return reformatted_counts\n",
    "    \n",
    "def pickle_to_matrix(reformatted_emb):    # Reading pickle file containing embeddings\n",
    "    matrix = pd.DataFrame(reformatted_emb)\n",
    "    matrix.index = [\"dimension\" + str(i) for i in range(1, matrix.shape[0]+1)]  # dimension as rows, each entry as a column\n",
    "    return matrix \n",
    "\n",
    "def match_ID(matrix, reformatted_counts):\n",
    "    matched_IDs = matrix.loc[:, matrix.columns.isin(reformatted_counts[\"ID\"].values)]\n",
    "    return matched_IDs\n",
    "\n",
    "def AnnData_Object(matched_ID):\n",
    "    \"\"\" anndata is a Python package for handling annotated data matrices in memory and on disk, \n",
    "        positioned between pandas and xarray\"\"\"\n",
    "    adata = anndata.AnnData(X=matching_matrix.values, obs=pd.DataFrame(index=matching_matrix.index))\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read pickle file containing embeddings and reformat to remove dash\n",
    "path = '/Users/leandro/Desktop/ai_data/data/embeddings_v2.pickle'\n",
    "emb_input = pickle_reader(path)\n",
    "reformatted_emb = reformat_pickle(emb_input)\n",
    "#reformatted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read ORF2_counts file and reformat to remove dash and dots by underscore\n",
    "path_counts = '/Users/leandro/Desktop/ai_data/data/ORF2p_counts.csv'\n",
    "ORF2_counts = pd.read_csv(path_counts)\n",
    "reformatted_counts = reformat_df(ORF2_counts)\n",
    "#reformatted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4668a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define matrix based on embeddings file and match to counts file \n",
    "matrix = pickle_to_matrix(reformatted_emb)\n",
    "#matrix\n",
    "matched_IDs = match_ID(matrix, reformatted_counts)\n",
    "#matched_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1cae3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(matrix.columns), len(reformated_counts.index), len(matched_IDs.columns))  # Test number of matchs between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d8bcefa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1024 × 720"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- Creating AnnData object \n",
    "adata = AnnData_Object(matched_IDs)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add counts\n",
    "ID_embeddings = pd.DataFrame(index=adata.obs.index)\n",
    "ID_embeddings_with_counts = pd.merge(ID_embeddings, ORF_counts, left_index=True, right_on=\"ID\", how=\"left\").sort_values(\"ID\")\n",
    "assert all(ID_embeddings.index == ID_embeddings_with_counts[\"ID\"])\n",
    "adata.obs[\"ORF_all_counts\"] = ID_embeddings_with_counts[\"All\"].values\n",
    "adata.obs[\"ORF_nonredundant_counts\"] = ID_embeddings_with_counts[\"Non_redundant\"].values\n",
    "\n",
    "# Scale data to use for PCA\n",
    "sc.pp.scale(adata)\n",
    "\n",
    "# Run PCA and visualize data\n",
    "pca = PCA(n_components=subset_matrix.shape[1])\n",
    "adata.obsm[\"X_pca\"] = pca.fit_transform(adata.X)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, use_rep=\"X_pca\")\n",
    "sc.tl.umap(adata, n_components=2, metric=\"cosine\")\n",
    "\n",
    "# Import Seurat library\n",
    "import scanpy as sc\n",
    "\n",
    "# Load data\n",
    "adata = sc.read_h5ad('your_file.h5ad')\n",
    "\n",
    "# Run PCA\n",
    "sc.pp.pca(adata, use_highly_variable=True)\n",
    "\n",
    "# Visualize PCA results\n",
    "sc.pl.pca(adata, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Select PCs for UMAP\n",
    "sc.pl.pca_variance_ratio(adata)\n",
    "sc.tl.pca(adata, n_comps=21)\n",
    "sc.pl.pca_variance_ratio(adata, log=True)\n",
    "\n",
    "# Run UMAP\n",
    "sc.pp.neighbors(adata, n_neighbors=30, n_pcs=21)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "# Visualize UMAP results\n",
    "sc.pl.umap(adata, color='ORF_nonredundant_counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix.dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d72ca",
   "metadata": {},
   "source": [
    "Note that some of the code in the original R script, such as saving plots to a PDF file, will need to be modified or removed for use in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seurat library\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to load data\n",
    "def load_data(filename):\n",
    "    return sc.read_h5ad(filename)\n",
    "\n",
    "# Define a function to run PCA\n",
    "def run_pca(data):\n",
    "    sc.pp.pca(data, use_highly_variable=True)\n",
    "    return data\n",
    "\n",
    "# Define a function to visualize PCA results\n",
    "def plot_pca(data):\n",
    "    sc.pl.pca(data, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Define a function to select PCs for UMAP\n",
    "def select_pcs(data):\n",
    "    sc.tl.pca(data, n_comps=21)\n",
    "    sc.pl.pca_variance_ratio(data, log=True)\n",
    "    return data\n",
    "\n",
    "# Define a function to run UMAP\n",
    "def run_umap(data):\n",
    "    sc.pp.neighbors(data, n_neighbors=30, n_pcs=21)\n",
    "    sc.tl.umap(data)\n",
    "    return data\n",
    "\n",
    "# Define a function to visualize UMAP results\n",
    "def plot_umap(data):\n",
    "    sc.pl.umap(data, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Load data\n",
    "adata = load_data('your_file.h5ad')\n",
    "\n",
    "# Run PCA\n",
    "adata = run_pca(adata)\n",
    "\n",
    "# Visualize PCA results\n",
    "plot_pca(adata)\n",
    "\n",
    "# Select PCs for UMAP\n",
    "adata = select_pcs(adata)\n",
    "\n",
    "# Run UMAP\n",
    "adata = run_umap(adata)\n",
    "\n",
    "# Visualize UMAP results\n",
    "plot_umap(adata)\n",
    "\n",
    "# Save UMAP plot as a PDF file\n",
    "plt.savefig('UMAP_1_2_plot.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code defines functions for loading data, running PCA, visualizing PCA results, selecting PCs for UMAP, running UMAP, visualizing UMAP results, and saving a UMAP plot as a PDF file.\n",
    "The main code loads the data, runs PCA, visualizes PCA results, selects PCs for UMAP, runs UMAP, visualizes UMAP results, and saves a U"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
