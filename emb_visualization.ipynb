{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import umap\n",
    "import scipy.sparse as sparse\n",
    "from scipy.io import mmwrite\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scanpy as sc\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80093be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_reader(path):\n",
    "    emb_input = pd.read_pickle(path)\n",
    "    return emb_input\n",
    "\n",
    "def reformat_pickle(emb_input):\n",
    "    \"\"\"Change every dash (-) by underscore to allow datasets merging\"\"\"\n",
    "    reformatted_emb = {}\n",
    "    for k, v in emb_input.items():\n",
    "        new_k = k.replace('-', '_')\n",
    "        v = v\n",
    "        reformatted_emb[new_k] = v\n",
    "    return reformatted_emb\n",
    "\n",
    "def reformat_df(ORF2_counts):\n",
    "    \"\"\"Change every dash (-) and dot (.) by underscore (_) to allow datasets merging\"\"\"\n",
    "    reformatted_counts_dict = {}\n",
    "    counts = ORF2_counts['Non_redundant']\n",
    "    names = ORF2_counts['ID']\n",
    "    for i in range(len(ORF2_counts)):\n",
    "        number = counts[i]\n",
    "        ID = names[i]\n",
    "        not_dash = ID.replace('-', '_')\n",
    "        clean = not_dash.replace('.', '_')\n",
    "        #print(clean)\n",
    "        reformatted_counts_dict[clean] = number\n",
    "        #reformatted_counts_dict\n",
    "    \n",
    "    reformatted = pd.DataFrame.from_dict(reformatted_counts_dict, orient='index')\n",
    "    reformatted_counts = reformatted.reset_index()\n",
    "    reformatted_counts.columns = ['ID', 'Non_redundant']\n",
    "    return reformatted_counts\n",
    "    \n",
    "def pickle_to_matrix(reformatted_emb):    # Reading pickle file containing embeddings\n",
    "    matrix_inverted = pd.DataFrame(reformatted_emb)  # Create df from emb dict\n",
    "    matrix = matrix_inverted.transpose()  # Invert rows and columns to make it fit for Anndata object\n",
    "    #matrix.index = [\"dimension\" + str(i) for i in range(1, matrix.shape[0]+1)]  # dimension as rows, each entry as a column\n",
    "    return matrix \n",
    "\n",
    "def match_ID(matrix, reformatted_counts):\n",
    "    \"\"\"Matching matrix (embs) and IDs from counts file to use embs observations with counts associated (all)\"\"\"\n",
    "   #matched_IDs = matrix.loc[:, matrix.index.isin(reformatted_counts[\"ID\"].values)]\n",
    "    matched_emb = matrix.loc[matrix.index.isin(reformatted_counts['ID'].values)]\n",
    "    matched_counts = reformatted_counts.loc[reformatted_counts['ID'].isin(matrix.index)] \n",
    "    return matched_emb, matched_counts\n",
    "\n",
    "def AnnData_Object(matched_emb):\n",
    "    \"\"\" anndata is a Python package for handling annotated data matrices in memory and on disk, \n",
    "        positioned between pandas and xarray\"\"\"\n",
    "    #adata = ad.AnnData(X=matched_IDs.index, obs=pd.DataFrame(index=matched_IDs.columns))\n",
    "    adata = ad.AnnData(X = matched_emb.values, obs = matched_emb.index.to_list(),var = matched_emb.columns.tolist())\n",
    "    return adata\n",
    "\n",
    "def add_counts(adata, matched_counts):\n",
    "    \"\"\"Including counts information in emb matrix\"\"\"\n",
    "    ID_embeddings = pd.DataFrame(matched_emb.index)\n",
    "    ID_embeddings.columns = [\"ID\"]\n",
    "    ID_embeddings_with_counts = pd.merge(ID_embeddings, matched_counts)\n",
    "    ID_embeddings_with_counts.columns = ['ID', 'Non_redundant']\n",
    "    #assert all(ID_embeddings.index == ID_embeddings_with_counts[\"ID\"])\n",
    "    #adata.obs[\"ORF_all_counts\"] = ID_embeddings_with_counts[\"All\"].values\n",
    "    adata.obs[\"Non_redundant\"] = pd.Categorical(ID_embeddings_with_counts[\"Non_redundant\"].values)\n",
    "    #return adata   # no need to return a variable, just modify adata object\n",
    "\n",
    "def run_pca(adata):\n",
    "    \"\"\"Define a function to run PCA and visualize\"\"\"\n",
    "    sc.pp.scale(adata) # Scale data for PCA\n",
    "    sc.pp.pca(adata, use_highly_variable=False)   # Run PCA over scaled data\n",
    "    sc.pl.pca(adata, annotate_var_explained=True, color='Non_redundant')   # Plot PCA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read pickle file containing embeddings and reformat to remove dash that block merge\n",
    "path = '/Users/leandro/Desktop/ai_data/data/embeddings_v2.pickle'\n",
    "emb_input = pickle_reader(path)\n",
    "reformatted_emb = reformat_pickle(emb_input)\n",
    "#reformatted_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Read ORF2_counts file and reformat to remove dash and dots by underscore\n",
    "path_counts = '/Users/leandro/Desktop/ai_data/data/ORF2p_counts.csv'\n",
    "ORF2_counts = pd.read_csv(path_counts)\n",
    "reformatted_counts = reformat_df(ORF2_counts)\n",
    "#reformatted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Creating matrix from reformatted_emb dict and filtering counts and emb dataset to same length\n",
    "matrix = pickle_to_matrix(reformatted_emb)\n",
    "#matrix\n",
    "matched_emb = match_ID(matrix, reformatted_counts)[0]\n",
    "#matches_emb\n",
    "matched_counts = match_ID(matrix, reformatted_counts)[1]\n",
    "#matched_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matrix.index), len(matched_emb.index), len(matched_counts.index))  # Test number of matchs between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f106d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- Create AnnData and including count information\n",
    "adata = AnnData_Object(matched_emb)\n",
    "#adata.obs\n",
    "add_counts(adata, matched_counts)\n",
    "#adata.shape\n",
    "adata.var_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0353ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pca(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a704b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Run PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up color gradient for labels (labels are stored in a column called \"Non_redundant\")\n",
    "label_colors = np.linspace(0, 1, len(np.unique(adata.obs[\"Non_redundant\"])))\n",
    "label_cmap = plt.cm.get_cmap(\"rainbow\")\n",
    "label_color_dict = dict(zip(np.unique(adata.obs[\"Non_redundant\"]), label_cmap(label_colors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f9b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot PCA with color bar\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sm = matplotlib.cm.ScalarMappable(norm=plt.Normalize(vmin=min(adata.obs[\"Non_redundant\"]), vmax=max(adata.obs[\"Non_redundant\"])), cmap=label_cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "sc.pl.pca(adata, annotate_var_explained=True, color=\"Non_redundant\", size=75, \n",
    "          ax=ax, show=False, cmap=label_cmap, legend_loc=False) # save='truñaco.pdf'\n",
    "cbar = plt.colorbar(sm, fraction=0.046, pad=0.04) # modify color bar \n",
    "cbar.ax.set_ylabel(\"Non_redundant\", rotation=270, labelpad=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA with color bar\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sm = matplotlib.cm.ScalarMappable(norm=plt.Normalize(vmin=min(adata.obs[\"Non_redundant\"]), vmax=max(adata.obs[\"Non_redundant\"])), cmap=label_cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "sc.pl.pca(adata, annotate_var_explained=True, color=\"Non_redundant\", size=75, \n",
    "          ax=ax, show=False, cmap=label_cmap, legend_loc=False) # save='truñaco.pdf'\n",
    "cbar = plt.colorbar(sm, fraction=0.046, pad=0.04) # modify color bar \n",
    "cbar.ax.set_ylabel(\"Non_redundant\", rotation=270, labelpad=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(adata.obs['Non_redundant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f087416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(adata.obs['Non_redundant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run PCA and visualize data\n",
    "pca = PCA(n_components=subset_matrix.shape[1])\n",
    "adata.obsm[\"X_pca\"] = pca.fit_transform(adata.X)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, use_rep=\"X_pca\")\n",
    "sc.tl.umap(adata, n_components=2, metric=\"cosine\")\n",
    "\n",
    "# Import Seurat library\n",
    "import scanpy as sc\n",
    "\n",
    "# Load data\n",
    "adata = sc.read_h5ad('your_file.h5ad')\n",
    "\n",
    "# Run PCA\n",
    "sc.pp.pca(adata, use_highly_variable=True)\n",
    "\n",
    "# Visualize PCA results\n",
    "sc.pl.pca(adata, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Select PCs for UMAP\n",
    "sc.pl.pca_variance_ratio(adata)\n",
    "sc.tl.pca(adata, n_comps=21)\n",
    "sc.pl.pca_variance_ratio(adata, log=True)\n",
    "\n",
    "# Run UMAP\n",
    "sc.pp.neighbors(adata, n_neighbors=30, n_pcs=21)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "# Visualize UMAP results\n",
    "sc.pl.umap(adata, color='ORF_nonredundant_counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix.dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d72ca",
   "metadata": {},
   "source": [
    "Note that some of the code in the original R script, such as saving plots to a PDF file, will need to be modified or removed for use in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7473f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seurat library\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to load data\n",
    "def load_data(filename):\n",
    "    return sc.read_h5ad(filename)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to visualize PCA results\n",
    "def plot_pca(data):\n",
    "    sc.pl.pca(data, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Define a function to select PCs for UMAP\n",
    "def select_pcs(data):\n",
    "    sc.tl.pca(data, n_comps=21)\n",
    "    sc.pl.pca_variance_ratio(data, log=True)\n",
    "    return data\n",
    "\n",
    "# Define a function to run UMAP\n",
    "def run_umap(data):\n",
    "    sc.pp.neighbors(data, n_neighbors=30, n_pcs=21)\n",
    "    sc.tl.umap(data)\n",
    "    return data\n",
    "\n",
    "# Define a function to visualize UMAP results\n",
    "def plot_umap(data):\n",
    "    sc.pl.umap(data, color='ORF_nonredundant_counts')\n",
    "\n",
    "# Load data\n",
    "adata = load_data('your_file.h5ad')\n",
    "\n",
    "# Run PCA\n",
    "adata = run_pca(adata)\n",
    "\n",
    "# Visualize PCA results\n",
    "plot_pca(adata)\n",
    "\n",
    "# Select PCs for UMAP\n",
    "adata = select_pcs(adata)\n",
    "\n",
    "# Run UMAP\n",
    "adata = run_umap(adata)\n",
    "\n",
    "# Visualize UMAP results\n",
    "plot_umap(adata)\n",
    "\n",
    "# Save UMAP plot as a PDF file\n",
    "plt.savefig('UMAP_1_2_plot.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code defines functions for loading data, running PCA, visualizing PCA results, selecting PCs for UMAP, running UMAP, visualizing UMAP results, and saving a UMAP plot as a PDF file.\n",
    "The main code loads the data, runs PCA, visualizes PCA results, selects PCs for UMAP, runs UMAP, visualizes UMAP results, and saves a U"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
