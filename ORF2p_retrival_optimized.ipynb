{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9li5Jzka3KH7"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install SeqIO\n",
    "!pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwLqbMuA3vn4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(input_path):\n",
    "    \"\"\"Reads Dfam dataset from a CSV file\"\"\"\n",
    "    df = pd.read_csv(input_path, low_memory=False)\n",
    "    return df\n",
    "\n",
    "def sort_and_select_columns(df):\n",
    "    \"\"\"Sorts the input dataframe and rename desired columns\"\"\"\n",
    "    sorted_df = df.iloc[:,[19, 3, 8, 18, 16]]\n",
    "    sorted_df.columns = ['ID','Length','DNA_seq', 'Counts', 'Species']\n",
    "    return sorted_df\n",
    "\n",
    "def filter_by_length(df, min_length=3000):\n",
    "    \"\"\"Filters out rows with Length less than the given min_length\"\"\"\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    filtered_df = df.loc[df['Length'] > min_length]\n",
    "    return filtered_df\n",
    "\n",
    "def retrieve_eukarya_class(filtered_df, eukarya_classes):\n",
    "    \"\"\"Retrieves the Eukarya class names from the Species column in the filtered dataframe\"\"\"\n",
    "    taxonomy = filtered_df['Species']\n",
    "    name = filtered_df['ID'] \n",
    "    taxo_dict = {}\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        spec = taxonomy.iloc[i]\n",
    "        parts = spec.split(\";\")\n",
    "        for word in parts:\n",
    "            if word in eukarya_classes:\n",
    "                taxo_dict[ID] = word\n",
    "    # Make a dataframe and set ID column as index\n",
    "    taxo_info = pd.DataFrame.from_dict(taxo_dict, orient='index') \n",
    "    L1_taxo = taxo_info.reset_index() \n",
    "    L1_taxo.columns = ['ID', 'Taxonomy']\n",
    "    return L1_taxo\n",
    "\n",
    "def retrieve_count_number(filtered_df):\n",
    "    \"\"\"Retrieves count numbers from the Counts column in the filtered dataframe\"\"\"\n",
    "    name = filtered_df['ID']  \n",
    "    counts = filtered_df['Counts']\n",
    "    output_dict = {}\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        if type(counts.iloc[i]) == str:\n",
    "            hmm_dict = eval(counts.iloc[i])\n",
    "            count_list = list(hmm_dict.values())  \n",
    "            count_dict = eval(str(count_list[0])) \n",
    "            all_count = count_dict['gathering_all']\n",
    "            non_redun = count_dict['gathering_nonredundant']\n",
    "            output_dict[ID] = (all_count,non_redun)\n",
    "    # Make a dataframe and set ID column as index\n",
    "    count_df = pd.DataFrame.from_dict(output_dict, orient='index').reset_index() \n",
    "    # Rename cols\n",
    "    ORF2p_counts.columns = ['ID','All', 'Non_redundant']\n",
    "    return ORF2p_counts\n",
    "\n",
    "def extract_protein_sequences(filtered_df):\n",
    "    \"\"\"Look for ORFs in all the possible frames (6)\"\"\"\n",
    "    prot_dict = {}\n",
    "    name = filtered_df['ID']\n",
    "    DNA = filtered_df['DNA_seq']\n",
    "\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        if type(DNA.iloc[i]) == str:\n",
    "            record = Seq(DNA.iloc[i])\n",
    "            for strand, nuc in [(+1, record), (-1, record.reverse_complement())]:\n",
    "                for frame in range(3):\n",
    "                    min_pro_len = 1000\n",
    "                    table = 1\n",
    "                    length = 3 * ((len(record) - frame) // 3)\n",
    "                    for pro in nuc[frame : frame + length].translate(table).split(\"*\"):\n",
    "                        if len(pro) >= min_pro_len:\n",
    "                            prot_dict[ID] = str(pro)\n",
    "    \n",
    "    proteins_df = pd.DataFrame.from_dict(prot_dict, orient='index', columns=['protein_sequence'])\n",
    "    proteins_df.index.name = 'ID'\n",
    "    \n",
    "    return proteins_df\n",
    "\n",
    "def write_fasta(output_file, prot_dict):\n",
    "    \"\"\"Write protein dictionary into fasta format including ID as header (no description)\"\"\"\n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for seq_id, seq in prot_dict.items(): # loop through dictionary items \n",
    "            seq_record = SeqIO.SeqRecord(Seq(seq), id= str(seq_id), description=\"\") # make sure to save ID as string\n",
    "            SeqIO.write(seq_record, out_file, 'fasta')\n",
    "\n",
    "def merge_counts(proteins_df, ORF2p_counts):\n",
    "    \"\"\" Merging prots df and counts df\"\"\"\n",
    "    ORF2p_seqs_counts = pd.merge(proteins_df,ORF2p_counts)\n",
    "    return ORF2p_seqs_counts\n",
    "\n",
    "def merge_taxa(ORF2p_seqs_counts, L1_taxo):\n",
    "    \"\"\"Merging seqs_counts df with taxa info\"\"\"\n",
    "    ORF2p_with_taxo = pd.merge(ORF2p_seqs_counts, L1_taxo)\n",
    "    return ORF2p_with_taxo\n",
    "\n",
    "def export_to_csv(df, out_path):\n",
    "    \"\"\"Export df to local directorty // Include file name at the end the path\"\"\"\n",
    "    df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/Users/leandrojorqueravalero/Desktop/PhD/synthetic_ORF2/data/preprocessed_LINE_v2.csv\"\n",
    "df = read_dataset(input_path)\n",
    "#len(df.index) # -- Check df is read completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -- Select columns of interest\n",
    "sorted_df = sort_and_select_columns(df)\n",
    "#len(sorted_df.index) # -- Check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- Filtering according to DNA_seq length to extract only ORF2 or full L1\n",
    "filtered_df = filter_by_length(sorted_df, min_length=3000)\n",
    "#len(filtered_df.index)   # -- Show number of entries that remains after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define main eukarya classes (list from ChatGPT) extract from each entry based on matching to list\n",
    "eukarya_classes = ['Mammalia', 'Aves', 'Reptilia', 'Actinopterygii', 'Amphibia', 'Insecta', 'Fungi', 'Plantae']\n",
    "L1_taxo = retrieve_eukarya_class(filtered_df, eukarya_classes)\n",
    "#len(L1_taxo.index)  # -- Only 1342 entries out of 26k have Taxonomy label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ORF2p_counts = retrieve_count_number(filtered_df)\n",
    "#len(ORF2p_counts.index) # -- Only 1357 entries out of 26k have counts info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_df = extract_protein_sequences(filtered_df)\n",
    "len(proteins_df.index)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BNG40Ig6PX1L",
    "cZOBRtL_GQqB"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
