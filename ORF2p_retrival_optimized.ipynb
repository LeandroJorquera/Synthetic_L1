{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9li5Jzka3KH7"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install SeqIO\n",
    "!pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwLqbMuA3vn4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(input_path, min_length = 3000):\n",
    "    \"\"\"Reads Dfam dataset from CSV file, select columns and filter by DNA_seq length\"\"\"\n",
    "    df = pd.read_csv(input_path, low_memory=False)\n",
    "    sorted_df = df.iloc[:,[19, 3, 8, 18, 16]]\n",
    "    sorted_df.columns = ['ID','Length','DNA_seq', 'Counts', 'Species']\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    filtered_df = sorted_df.loc[sorted_df['Length'] > min_length]\n",
    "\n",
    "    return df, filtered_df\n",
    "\n",
    "def get_taxa(filtered_df, eukarya_classes):\n",
    "    \"\"\"Retrieves the Eukarya class names from the Species column in the filtered dataframe\"\"\"\n",
    "    taxonomy = filtered_df['Species']\n",
    "    name = filtered_df['ID'] \n",
    "    taxo_dict = {}\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        spec = taxonomy.iloc[i]\n",
    "        parts = spec.split(\";\")\n",
    "        for word in parts:\n",
    "            if word in eukarya_classes:\n",
    "                taxo_dict[ID] = word\n",
    "    # Make a dataframe and set ID column as index\n",
    "    taxo_info = pd.DataFrame.from_dict(taxo_dict, orient='index') \n",
    "    L1_taxo = taxo_info.reset_index() \n",
    "    L1_taxo.columns = ['ID', 'Taxonomy']\n",
    "    mammals_taxo = L1_taxo.loc[L1_taxo['Taxonomy'] == 'Mammalia']  # Select only mammals\n",
    "    return L1_taxo, mammals_taxo\n",
    "\n",
    "def get_count_number(filtered_df):\n",
    "    \"\"\"Retrieves count numbers from the Counts column in the filtered dataframe\"\"\"\n",
    "    name = filtered_df['ID']  \n",
    "    counts = filtered_df['Counts']\n",
    "    output_dict = {}\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        if type(counts.iloc[i]) == str:\n",
    "            hmm_dict = eval(counts.iloc[i])\n",
    "            count_list = list(hmm_dict.values())  \n",
    "            count_dict = eval(str(count_list[0])) \n",
    "            all_count = count_dict['gathering_all']\n",
    "            non_redun = count_dict['gathering_nonredundant']\n",
    "            output_dict[ID] = (all_count,non_redun)\n",
    "    # Make a dataframe and set ID column as index\n",
    "    count_df = pd.DataFrame.from_dict(output_dict, orient='index')\n",
    "    L1_counts = count_df.reset_index()\n",
    "    # Rename cols\n",
    "    L1_counts.columns = ['ID','All', 'Non_redundant']\n",
    "    return L1_counts\n",
    "\n",
    "def extract_protein_sequences(filtered_df):\n",
    "    \"\"\"Look for ORFs in all the possible frames (6)\"\"\"\n",
    "    prot_dict = {}\n",
    "    name = filtered_df['ID']\n",
    "    DNA = filtered_df['DNA_seq']\n",
    "\n",
    "    for i in range(len(filtered_df)):\n",
    "        ID = name.iloc[i]\n",
    "        if type(DNA.iloc[i]) == str:\n",
    "            record = Seq(DNA.iloc[i])\n",
    "            for strand, nuc in [(+1, record), (-1, record.reverse_complement())]:\n",
    "                for frame in range(3):\n",
    "                    min_pro_len = 1000\n",
    "                    table = 1\n",
    "                    length = 3 * ((len(record) - frame) // 3)\n",
    "                    for pro in nuc[frame : frame + length].translate(table).split(\"*\"):\n",
    "                        if len(pro) >= min_pro_len:\n",
    "                            prot_dict[ID] = str(pro)\n",
    "    # Generating prot_df from prot_dict\n",
    "    prot_df = pd.DataFrame.from_dict(prot_dict, orient='index')\n",
    "    proteins_df = prot_df.reset_index()\n",
    "    proteins_df.columns = ['ID','prot_seq']\n",
    "    \n",
    "        \n",
    "    # Write protein dictionary into fasta format including ID as header (no description) in working directory\n",
    "    output_file = 'ORF2p_newfinder.fasta'  # Output filename\n",
    "    \n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for seq_id, seq in prot_dict.items(): # loop through dictionary items \n",
    "            seq_record = SeqIO.SeqRecord(Seq(seq), id= str(seq_id), description=\"\") # make sure to save ID as string\n",
    "            SeqIO.write(seq_record, out_file, 'fasta')\n",
    "    \n",
    "    return prot_dict, proteins_df  # return both dict (from exporting as fasta) and df for merging\n",
    "\n",
    "def merge_df(proteins_df, ORF2p_counts):\n",
    "    \"\"\" Merging prots df and counts df\"\"\"\n",
    "    ORF2_with_counts = pd.merge(proteins_df,ORF2p_counts)\n",
    "    ORF2p_taxo = pd.merge(ORF2_with_counts, L1_taxo)\n",
    "    ORF2p_mammals = pd.merge(ORF2_with_counts, mammals_taxo)\n",
    "    \n",
    "\n",
    "    return ORF2_with_counts, ORF2p_taxo, ORF2p_mammals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORFinder that look for M as the first residue (render less prots)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prot_orfs(filtered_df):\n",
    "    \"\"\"Look for ORFs in all the possible frames (6)\"\"\"\n",
    "    prot_dict = {}\n",
    "    min_pro_len = 1000  # Set the minimum length of a protein sequence\n",
    "\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        ID = row['ID']\n",
    "        DNA = row['DNA_seq']\n",
    "        if isinstance(DNA, str):\n",
    "            record = Seq(DNA) # Generate Seq object from string DNA seq\n",
    "            # Iterate through both strands of the DNA sequence (forward and reverse complement)\n",
    "            for strand, nuc in [(+1, record), (-1, record.reverse_complement())]: \n",
    "                # Explore all 6 possible ORFs\n",
    "                for frame in range(3):\n",
    "                    length = 3 * ((len(record) - frame) // 3)\n",
    "                    orfs = [str(pro) for pro in nuc[frame : frame + length].translate(table=1).split(\"*\") if str(pro).startswith('M')]\n",
    "                    if orfs:\n",
    "                        seq_final = max(orfs, key=len)\n",
    "                        if len(seq_final) >= min_pro_len:\n",
    "                            prot_dict[ID] = seq_final\n",
    "                            break\n",
    "                            \n",
    "    # Generating prot_df from prot_dict\n",
    "    prot_df = pd.DataFrame.from_dict(prot_dict, orient='index')\n",
    "    proteins_df = prot_df.reset_index()\n",
    "    proteins_df.columns = ['ID','prot_seq']\n",
    "    \n",
    "    # Write protein dictionary into fasta format including ID as header (no description) in working directory\n",
    "    output_file = 'ORF2p_newfinder.fasta'\n",
    "    \n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for seq_id, seq in prot_dict.items(): # loop through dictionary items \n",
    "            seq_record = SeqIO.SeqRecord(Seq(seq), id= str(seq_id), description=\"\") # make sure to save ID as string\n",
    "            SeqIO.write(seq_record, out_file, 'fasta')\n",
    "\n",
    "                            \n",
    "    return proteins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/Users/leandro/Desktop/ai_data/data/preprocessed_LINE_v2.csv\"\n",
    "df = read_dataset(input_path)[0]\n",
    "filtered_df = read_dataset(input_path)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df.index) # -- Check df is read completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -- Select columns of interest\n",
    "sorted_df = sort_and_select_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(filtered_df.index) # -- Check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define main eukarya classes (list from ChatGPT) extract from each entry based on matching to list\n",
    "eukarya_classes = ['Mammalia', 'Aves', 'Reptilia', 'Actinopterygii', 'Amphibia', 'Insecta', 'Fungi', 'Plantae']\n",
    "L1_taxo = get_taxa(filtered_df, eukarya_classes)[0]\n",
    "mammals_taxo = get_taxa(filtered_df, eukarya_classes)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(L1_taxo.index)  # -- Only 1342 entries out of 26k have Taxonomy label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mammals_taxo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L1_counts = get_count_number(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(L1_counts.index) # -- Only 1357 entries out of 26k have counts info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_orf = extract_protein_sequences(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#prot_dict\n",
    "#proteins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prot_orfs(filtered_df):\n",
    "    \"\"\"Look for ORFs in all the possible frames (6)\"\"\"\n",
    "    prot_dict = {}\n",
    "    min_pro_len = 1000  # Set the minimum length of a protein sequence\n",
    "\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        ID = row['ID']\n",
    "        DNA = row['DNA_seq']\n",
    "        if isinstance(DNA, str):\n",
    "            record = Seq(DNA) # Generate Seq object from string DNA seq\n",
    "            # Iterate through both strands of the DNA sequence (forward and reverse complement)\n",
    "            for strand, nuc in [(+1, record), (-1, record.reverse_complement())]: \n",
    "                # Explore all 6 possible ORFs\n",
    "                for frame in range(3):\n",
    "                    length = 3 * ((len(record) - frame) // 3)\n",
    "                    orfs = [str(pro) for pro in nuc[frame : frame + length].translate(table=1).split(\"*\") if str(pro).startswith('M')]\n",
    "                    if orfs:\n",
    "                        seq_final = max(orfs, key=len)\n",
    "                        if len(seq_final) >= min_pro_len:\n",
    "                            prot_dict[ID] = seq_final\n",
    "                            break\n",
    "                            \n",
    "    # Generating prot_df from prot_dict\n",
    "    prot_df = pd.DataFrame.from_dict(prot_dict, orient='index')\n",
    "    proteins_df = prot_df.reset_index()\n",
    "    proteins_df.columns = ['ID','prot_seq']\n",
    "    \n",
    "    # Write protein dictionary into fasta format including ID as header (no description) in working directory\n",
    "    output_file = 'ORF2p_newfinder.fasta'\n",
    "    \n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for seq_id, seq in prot_dict.items(): # loop through dictionary items \n",
    "            seq_record = SeqIO.SeqRecord(Seq(seq), id= str(seq_id), description=\"\") # make sure to save ID as string\n",
    "            SeqIO.write(seq_record, out_file, 'fasta')\n",
    "\n",
    "                            \n",
    "    return prot_dict, proteins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "main()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_df = get_prot_orfs(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prot_df.index)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BNG40Ig6PX1L",
    "cZOBRtL_GQqB"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
